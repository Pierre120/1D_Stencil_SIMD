{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1-D Stencil using CUDA\n",
        "\n",
        "CEPARCO SIMD Deep Dive programming project.\n",
        "\n",
        "#### Author:\n",
        "- HERNANDEZ, Pierre Vincent"
      ],
      "metadata": {
        "id": "wN_aj0dCfXHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`2^20`**"
      ],
      "metadata": {
        "id": "a1lN8JgMnf_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_wDX0E7fSzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8e72ca-9c63-4357-9a69-e382f6b1bcb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing stencil_CUDA_2-20.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile stencil_CUDA_2-20.cu\n",
        "// Name: HERNANDEZ, Pierre Vincent C.\t\tCEPARCO - S11\n",
        "// About: 1-D Stencil using CUDA\n",
        "// Number of elements: 2^20\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// CUDA init kernel\n",
        "__global__\n",
        "void stencil_1D_CUDA(long long int* Y, long long int* X, int n) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i > 2 && i < n - 3; i += stride) {\n",
        "    Y[i] = X[i - 3] + X[i - 2] + X[i - 1] + X[i] + X[i + 1] + X[i + 2] + X[i + 3];\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "// CUDA init kernel\n",
        "__global__\n",
        "void initY(int n, long long int* Y) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    Y[i] = 0L;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main(void) {\n",
        "  const int n = 1<<20;\n",
        "  const long long int VECTOR_BYTES = n * sizeof(long long int);\n",
        "  const int RUN_COUNT = 30;\n",
        "\n",
        "  // Allocate memory for vectors\n",
        "\tlong long int *X, *Y;\n",
        "  cudaMallocManaged(&X, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&Y, VECTOR_BYTES);\n",
        "\n",
        "  // Display current specs\n",
        "\tprintf(\"\\n=== 1-D Stencil ===\\n\");\n",
        "\tprintf(\"Number of elements (n):  %d\\n\", n);\n",
        "\tprintf(\"Byte size per vector:  %lld\\n\", VECTOR_BYTES);\n",
        "\tprintf(\"Number of runs:  %d\\n\\n\", RUN_COUNT);\n",
        "\n",
        "  // Setup number of GPU threads and blocks to be used\n",
        "  int numThreads = 1024; // maximize threads\n",
        "  int numBlocks = (n + numThreads - 1) / numThreads;\n",
        "  printf(\"Num. of Threads = %d\\nNum. of Blocks = %d\\n\", numThreads, numBlocks);\n",
        "\n",
        "  // Setup where X vector is going to be located\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device); // get device number of GPU\n",
        "  printf(\"Device # = %d\\n\", device);\n",
        "  // Advise GPU that the `X` vector stays in the host memory -- copy and paste\n",
        "  cudaMemAdvise(X, VECTOR_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(X, VECTOR_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        "  // Asynchronously transfer data ahead of time to the GPU memory -- Cut and paste\n",
        "  cudaMemPrefetchAsync(Y, VECTOR_BYTES, device, NULL); // NULL means run one stream\n",
        "\n",
        "  //init data\n",
        "  for(int i = 0; i < n; i++){\n",
        "    X[i] = (long long int)(i + 1);\n",
        "  }\n",
        "  initY <<<numBlocks, numThreads>>> (n, Y);\n",
        "\n",
        "  // Advise GPU that the `X` array is read only\n",
        "  cudaMemAdvise(X, VECTOR_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  // Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(X, VECTOR_BYTES, device, NULL); // NULL means run one stream\n",
        "\n",
        "\n",
        "  // Run stencil kernel many times\n",
        "  for(int i = 0; i < RUN_COUNT; i++) {\n",
        "    stencil_1D_CUDA <<<numBlocks, numThreads>>> (Y, X, n);\n",
        "  }\n",
        "  //wait to return from GPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(Y, VECTOR_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i = 3; i < n - 3; i++) {\n",
        "    if(Y[i] != (X[i - 3] + X[i - 2] + X[i - 1] + X[i] + X[i + 1] + X[i + 2] + X[i + 3]))\n",
        "      ++err_count;\n",
        "  }\n",
        "  printf(\"Error count (CUDA program): %d \\n\\n\", err_count);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(X);\n",
        "  cudaFree(Y);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc stencil_CUDA_2-20.cu -o stencil_CUDA_2-20"
      ],
      "metadata": {
        "id": "8fBl-IJ9n9so",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450d167b-9a4d-4759-87e3-d24bbbf1a0b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./stencil_CUDA_2-20"
      ],
      "metadata": {
        "id": "WMx2fOI4oDNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6426e1-5025-4cfb-feae-90d0917ad5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==913== NVPROF is profiling process 913, command: ./stencil_CUDA_2-20\n",
            "\n",
            "=== 1-D Stencil ===\n",
            "Number of elements (n):  1048576\n",
            "Byte size per vector:  8388608\n",
            "Number of runs:  30\n",
            "\n",
            "Num. of Threads = 1024\n",
            "Num. of Blocks = 1024\n",
            "Device # = 0\n",
            "Error count (CUDA program): 0 \n",
            "\n",
            "==913== Profiling application: ./stencil_CUDA_2-20\n",
            "==913== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   98.34%  2.9165ms        30  97.215us  94.303us  98.848us  stencil_1D_CUDA(__int64*, __int64*, int)\n",
            "                    1.66%  49.087us         1  49.087us  49.087us  49.087us  initY(int, __int64*)\n",
            "      API calls:   97.63%  423.56ms         2  211.78ms  50.003us  423.51ms  cudaMallocManaged\n",
            "                    1.09%  4.7476ms         4  1.1869ms  200.55us  2.7448ms  cudaMemPrefetchAsync\n",
            "                    0.74%  3.1991ms         1  3.1991ms  3.1991ms  3.1991ms  cudaDeviceSynchronize\n",
            "                    0.35%  1.5109ms         2  755.47us  699.63us  811.31us  cudaFree\n",
            "                    0.11%  462.39us         2  231.19us  16.752us  445.63us  cudaMemAdvise\n",
            "                    0.04%  178.15us        31  5.7460us  3.3380us  41.480us  cudaLaunchKernel\n",
            "                    0.04%  152.24us       101  1.5070us     155ns  51.830us  cuDeviceGetAttribute\n",
            "                    0.01%  26.075us         1  26.075us  26.075us  26.075us  cuDeviceGetName\n",
            "                    0.00%  6.7580us         1  6.7580us  6.7580us  6.7580us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.5650us         1  3.5650us  3.5650us  3.5650us  cudaGetDevice\n",
            "                    0.00%  1.8300us         3     610ns     225ns  1.3530us  cuDeviceGetCount\n",
            "                    0.00%     964ns         2     482ns     220ns     744ns  cuDeviceGet\n",
            "                    0.00%     493ns         1     493ns     493ns     493ns  cuDeviceTotalMem\n",
            "                    0.00%     388ns         1     388ns     388ns     388ns  cuModuleGetLoadingMode\n",
            "                    0.00%     269ns         1     269ns     269ns     269ns  cuDeviceGetUuid\n",
            "\n",
            "==913== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "       4  2.0000MB  2.0000MB  2.0000MB  8.000000MB  771.1010us  Host To Device\n",
            "       4  2.0000MB  2.0000MB  2.0000MB  8.000000MB  735.3900us  Device To Host\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`2^24`**"
      ],
      "metadata": {
        "id": "oexutCgAqs5W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c1f028-73d5-4b87-997f-e4a062bf52fc",
        "id": "bikMn2I3qs5X"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing stencil_CUDA_2-24.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile stencil_CUDA_2-24.cu\n",
        "// Name: HERNANDEZ, Pierre Vincent C.\t\tCEPARCO - S11\n",
        "// About: 1-D Stencil using CUDA\n",
        "// Number of elements: 2^24\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// CUDA init kernel\n",
        "__global__\n",
        "void stencil_1D_CUDA(long long int* Y, long long int* X, int n) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i > 2 && i < n - 3; i += stride) {\n",
        "    Y[i] = X[i - 3] + X[i - 2] + X[i - 1] + X[i] + X[i + 1] + X[i + 2] + X[i + 3];\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "// CUDA init kernel\n",
        "__global__\n",
        "void initY(int n, long long int* Y) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    Y[i] = 0L;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main(void) {\n",
        "  const int n = 1<<24;\n",
        "  const long long int VECTOR_BYTES = n * sizeof(long long int);\n",
        "  const int RUN_COUNT = 30;\n",
        "\n",
        "  // Allocate memory for vectors\n",
        "\tlong long int *X, *Y;\n",
        "  cudaMallocManaged(&X, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&Y, VECTOR_BYTES);\n",
        "\n",
        "  // Display current specs\n",
        "\tprintf(\"\\n=== 1-D Stencil ===\\n\");\n",
        "\tprintf(\"Number of elements (n):  %d\\n\", n);\n",
        "\tprintf(\"Byte size per vector:  %lld\\n\", VECTOR_BYTES);\n",
        "\tprintf(\"Number of runs:  %d\\n\\n\", RUN_COUNT);\n",
        "\n",
        "  // Setup number of GPU threads and blocks to be used\n",
        "  int numThreads = 1024; // maximize threads\n",
        "  int numBlocks = (n + numThreads - 1) / numThreads;\n",
        "  printf(\"Num. of Threads = %d\\nNum. of Blocks = %d\\n\", numThreads, numBlocks);\n",
        "\n",
        "  // Setup where X vector is going to be located\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device); // get device number of GPU\n",
        "  printf(\"Device # = %d\\n\", device);\n",
        "  // Advise GPU that the `X` vector stays in the host memory -- copy and paste\n",
        "  cudaMemAdvise(X, VECTOR_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(X, VECTOR_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        "  // Asynchronously transfer data ahead of time to the GPU memory -- Cut and paste\n",
        "  cudaMemPrefetchAsync(Y, VECTOR_BYTES, device, NULL); // NULL means run one stream\n",
        "\n",
        "  //init data\n",
        "  for(int i = 0; i < n; i++){\n",
        "    X[i] = (long long int)(i + 1);\n",
        "  }\n",
        "  initY <<<numBlocks, numThreads>>> (n, Y);\n",
        "\n",
        "  // Advise GPU that the `X` array is read only\n",
        "  cudaMemAdvise(X, VECTOR_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  // Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(X, VECTOR_BYTES, device, NULL); // NULL means run one stream\n",
        "\n",
        "\n",
        "  // Run stencil kernel many times\n",
        "  for(int i = 0; i < RUN_COUNT; i++) {\n",
        "    stencil_1D_CUDA <<<numBlocks, numThreads>>> (Y, X, n);\n",
        "  }\n",
        "  //wait to return from GPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(Y, VECTOR_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i = 3; i < n - 3; i++) {\n",
        "    if(Y[i] != (X[i - 3] + X[i - 2] + X[i - 1] + X[i] + X[i + 1] + X[i + 2] + X[i + 3]))\n",
        "      ++err_count;\n",
        "  }\n",
        "  printf(\"Error count (CUDA program): %d \\n\\n\", err_count);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(X);\n",
        "  cudaFree(Y);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc stencil_CUDA_2-24.cu -o stencil_CUDA_2-24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0febd8-3b68-496c-b2c9-cc6ae58a731d",
        "id": "Vh-lwHzGqs5Z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./stencil_CUDA_2-24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307bab3f-622d-4e05-e1ec-c1706db02629",
        "id": "-xS4APqXqs5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==991== NVPROF is profiling process 991, command: ./stencil_CUDA_2-24\n",
            "\n",
            "=== 1-D Stencil ===\n",
            "Number of elements (n):  16777216\n",
            "Byte size per vector:  134217728\n",
            "Number of runs:  30\n",
            "\n",
            "Num. of Threads = 1024\n",
            "Num. of Blocks = 16384\n",
            "Device # = 0\n",
            "Error count (CUDA program): 0 \n",
            "\n",
            "==991== Profiling application: ./stencil_CUDA_2-24\n",
            "==991== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   98.42%  44.254ms        30  1.4751ms  1.4704ms  1.4827ms  stencil_1D_CUDA(__int64*, __int64*, int)\n",
            "                    1.58%  712.29us         1  712.29us  712.29us  712.29us  initY(int, __int64*)\n",
            "      API calls:   60.80%  245.35ms         2  122.68ms  63.185us  245.29ms  cudaMallocManaged\n",
            "                   17.83%  71.958ms         4  17.989ms  994.77us  44.498ms  cudaMemPrefetchAsync\n",
            "                   12.43%  50.146ms         1  50.146ms  50.146ms  50.146ms  cudaDeviceSynchronize\n",
            "                    6.34%  25.601ms         2  12.801ms  12.791ms  12.811ms  cudaFree\n",
            "                    2.49%  10.052ms         2  5.0259ms  14.760us  10.037ms  cudaMemAdvise\n",
            "                    0.06%  226.85us        31  7.3170us  3.2800us  63.089us  cudaLaunchKernel\n",
            "                    0.04%  149.87us       101  1.4830us     134ns  71.676us  cuDeviceGetAttribute\n",
            "                    0.01%  26.915us         1  26.915us  26.915us  26.915us  cuDeviceGetName\n",
            "                    0.00%  7.5940us         1  7.5940us  7.5940us  7.5940us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.1470us         1  3.1470us  3.1470us  3.1470us  cudaGetDevice\n",
            "                    0.00%  1.9020us         3     634ns     257ns  1.3290us  cuDeviceGetCount\n",
            "                    0.00%     999ns         2     499ns     294ns     705ns  cuDeviceGet\n",
            "                    0.00%     734ns         1     734ns     734ns     734ns  cuDeviceTotalMem\n",
            "                    0.00%     387ns         1     387ns     387ns     387ns  cuModuleGetLoadingMode\n",
            "                    0.00%     230ns         1     230ns     230ns     230ns  cuDeviceGetUuid\n",
            "\n",
            "==991== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  14.45708ms  Host To Device\n",
            "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  10.80204ms  Device To Host\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`2^28`**"
      ],
      "metadata": {
        "id": "uZSZuCJ2q0K5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b0ced8-f863-401e-c091-abce74ffe230",
        "id": "w8cLNG4Dq0K6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing stencil_CUDA_2-28.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile stencil_CUDA_2-28.cu\n",
        "// Name: HERNANDEZ, Pierre Vincent C.\t\tCEPARCO - S11\n",
        "// About: 1-D Stencil using CUDA\n",
        "// Number of elements: 2^28\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// CUDA init kernel\n",
        "__global__\n",
        "void stencil_1D_CUDA(long long int* Y, long long int* X, int n) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i > 2 && i < n - 3; i += stride) {\n",
        "    Y[i] = X[i - 3] + X[i - 2] + X[i - 1] + X[i] + X[i + 1] + X[i + 2] + X[i + 3];\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "// CUDA init kernel\n",
        "__global__\n",
        "void initY(int n, long long int* Y) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    Y[i] = 0L;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main(void) {\n",
        "  const int n = 1<<28;\n",
        "  const long long int VECTOR_BYTES = n * sizeof(long long int);\n",
        "  const int RUN_COUNT = 30;\n",
        "\n",
        "  // Allocate memory for vectors\n",
        "\tlong long int *X, *Y;\n",
        "  cudaMallocManaged(&X, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&Y, VECTOR_BYTES);\n",
        "\n",
        "  // Display current specs\n",
        "\tprintf(\"\\n=== 1-D Stencil ===\\n\");\n",
        "\tprintf(\"Number of elements (n):  %d\\n\", n);\n",
        "\tprintf(\"Byte size per vector:  %lld\\n\", VECTOR_BYTES);\n",
        "\tprintf(\"Number of runs:  %d\\n\\n\", RUN_COUNT);\n",
        "\n",
        "  // Setup number of GPU threads and blocks to be used\n",
        "  int numThreads = 1024; // maximize threads\n",
        "  int numBlocks = (n + numThreads - 1) / numThreads;\n",
        "  printf(\"Num. of Threads = %d\\nNum. of Blocks = %d\\n\", numThreads, numBlocks);\n",
        "\n",
        "  // Setup where X vector is going to be located\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device); // get device number of GPU\n",
        "  printf(\"Device # = %d\\n\", device);\n",
        "  // Advise GPU that the `X` vector stays in the host memory -- copy and paste\n",
        "  cudaMemAdvise(X, VECTOR_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(X, VECTOR_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        "  // Asynchronously transfer data ahead of time to the GPU memory -- Cut and paste\n",
        "  cudaMemPrefetchAsync(Y, VECTOR_BYTES, device, NULL); // NULL means run one stream\n",
        "\n",
        "  //init data\n",
        "  for(int i = 0; i < n; i++){\n",
        "    X[i] = (long long int)(i + 1);\n",
        "  }\n",
        "  initY <<<numBlocks, numThreads>>> (n, Y);\n",
        "\n",
        "  // Advise GPU that the `X` array is read only\n",
        "  cudaMemAdvise(X, VECTOR_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  // Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(X, VECTOR_BYTES, device, NULL); // NULL means run one stream\n",
        "\n",
        "\n",
        "  // Run stencil kernel many times\n",
        "  for(int i = 0; i < RUN_COUNT; i++) {\n",
        "    stencil_1D_CUDA <<<numBlocks, numThreads>>> (Y, X, n);\n",
        "  }\n",
        "  //wait to return from GPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(Y, VECTOR_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i = 3; i < n - 3; i++) {\n",
        "    if(Y[i] != (X[i - 3] + X[i - 2] + X[i - 1] + X[i] + X[i + 1] + X[i + 2] + X[i + 3]))\n",
        "      ++err_count;\n",
        "  }\n",
        "  printf(\"Error count (CUDA program): %d \\n\\n\", err_count);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(X);\n",
        "  cudaFree(Y);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc stencil_CUDA_2-28.cu -o stencil_CUDA_2-28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc9fb79-c85d-4ee6-8531-08a6cff23040",
        "id": "cL22REgTq0K7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./stencil_CUDA_2-28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0ba40b-9cc0-4462-eaad-ffbe34c7dcef",
        "id": "lnAgeBy_q0K8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1079== NVPROF is profiling process 1079, command: ./stencil_CUDA_2-28\n",
            "\n",
            "=== 1-D Stencil ===\n",
            "Number of elements (n):  268435456\n",
            "Byte size per vector:  2147483648\n",
            "Number of runs:  30\n",
            "\n",
            "Num. of Threads = 1024\n",
            "Num. of Blocks = 262144\n",
            "Device # = 0\n",
            "Error count (CUDA program): 0 \n",
            "\n",
            "==1079== Profiling application: ./stencil_CUDA_2-28\n",
            "==1079== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   97.90%  528.99ms        30  17.633ms  17.445ms  20.853ms  stencil_1D_CUDA(__int64*, __int64*, int)\n",
            "                    2.10%  11.326ms         1  11.326ms  11.326ms  11.326ms  initY(int, __int64*)\n",
            "      API calls:   52.75%  1.34181s         4  335.45ms  14.713ms  662.67ms  cudaMemPrefetchAsync\n",
            "                   20.79%  528.90ms         1  528.90ms  528.90ms  528.90ms  cudaDeviceSynchronize\n",
            "                   12.79%  325.37ms         2  162.69ms  156.63ms  168.74ms  cudaFree\n",
            "                    9.54%  242.70ms         2  121.35ms  49.057us  242.65ms  cudaMallocManaged\n",
            "                    4.11%  104.58ms         2  52.292ms  19.414us  104.56ms  cudaMemAdvise\n",
            "                    0.01%  217.83us        31  7.0260us  3.3040us  52.785us  cudaLaunchKernel\n",
            "                    0.00%  124.65us       101  1.2340us     136ns  47.309us  cuDeviceGetAttribute\n",
            "                    0.00%  24.865us         1  24.865us  24.865us  24.865us  cuDeviceGetName\n",
            "                    0.00%  7.0540us         1  7.0540us  7.0540us  7.0540us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.7300us         1  2.7300us  2.7300us  2.7300us  cudaGetDevice\n",
            "                    0.00%  1.3510us         3     450ns     165ns     950ns  cuDeviceGetCount\n",
            "                    0.00%  1.2420us         2     621ns     182ns  1.0600us  cuDeviceGet\n",
            "                    0.00%     517ns         1     517ns     517ns     517ns  cuModuleGetLoadingMode\n",
            "                    0.00%     475ns         1     475ns     475ns     475ns  cuDeviceTotalMem\n",
            "                    0.00%     223ns         1     223ns     223ns     223ns  cuDeviceGetUuid\n",
            "\n",
            "==1079== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "    1024  2.0000MB  2.0000MB  2.0000MB  2.000000GB  184.6297ms  Host To Device\n",
            "    1024  2.0000MB  2.0000MB  2.0000MB  2.000000GB  164.4463ms  Device To Host\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`2^30`**"
      ],
      "metadata": {
        "id": "FE_FTdO_q4o7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453b4aa3-cbec-47ca-861b-569d23ca0fec",
        "id": "yjttUbZUq4o8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing stencil_CUDA_2-30.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile stencil_CUDA_2-30.cu\n",
        "// Name: HERNANDEZ, Pierre Vincent C.\t\tCEPARCO - S11\n",
        "// About: 1-D Stencil using CUDA\n",
        "// Number of elements: 2^30\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// CUDA init kernel\n",
        "__global__\n",
        "void stencil_1D_CUDA(long long int* Y, long long int* X, int n) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i > 2 && i < n - 3; i += stride) {\n",
        "    Y[i] = X[i - 3] + X[i - 2] + X[i - 1] + X[i] + X[i + 1] + X[i + 2] + X[i + 3];\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "// CUDA init kernel\n",
        "__global__\n",
        "void initY(int n, long long int* Y) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    Y[i] = 0L;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main(void) {\n",
        "  const int n = 1<<30;\n",
        "  const long long int VECTOR_BYTES = n * sizeof(long long int);\n",
        "  const int RUN_COUNT = 30;\n",
        "\n",
        "  // Allocate memory for vectors\n",
        "\tlong long int *X, *Y;\n",
        "  cudaMallocManaged(&X, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&Y, VECTOR_BYTES);\n",
        "\n",
        "  // Display current specs\n",
        "\tprintf(\"\\n=== 1-D Stencil ===\\n\");\n",
        "\tprintf(\"Number of elements (n):  %d\\n\", n);\n",
        "\tprintf(\"Byte size per vector:  %lld\\n\", VECTOR_BYTES);\n",
        "\tprintf(\"Number of runs:  %d\\n\\n\", RUN_COUNT);\n",
        "\n",
        "  // Setup number of GPU threads and blocks to be used\n",
        "  int numThreads = 1024; // maximize threads\n",
        "  int numBlocks = (n + numThreads - 1) / numThreads;\n",
        "  printf(\"Num. of Threads = %d\\nNum. of Blocks = %d\\n\", numThreads, numBlocks);\n",
        "\n",
        "  // Setup where X vector is going to be located\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device); // get device number of GPU\n",
        "  printf(\"Device # = %d\\n\", device);\n",
        "  // Advise GPU that the `X` vector stays in the host memory -- copy and paste\n",
        "  cudaMemAdvise(X, VECTOR_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(X, VECTOR_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        "  // Asynchronously transfer data ahead of time to the GPU memory -- Cut and paste\n",
        "  cudaMemPrefetchAsync(Y, VECTOR_BYTES, device, NULL); // NULL means run one stream\n",
        "\n",
        "  //init data\n",
        "  for(int i = 0; i < n; i++){\n",
        "    X[i] = (long long int)(i + 1);\n",
        "  }\n",
        "  initY <<<numBlocks, numThreads>>> (n, Y);\n",
        "\n",
        "  // Advise GPU that the `X` array is read only\n",
        "  cudaMemAdvise(X, VECTOR_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  // Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(X, VECTOR_BYTES, device, NULL); // NULL means run one stream\n",
        "\n",
        "\n",
        "  // Run stencil kernel many times\n",
        "  for(int i = 0; i < RUN_COUNT; i++) {\n",
        "    stencil_1D_CUDA <<<numBlocks, numThreads>>> (Y, X, n);\n",
        "  }\n",
        "  //wait to return from GPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(Y, VECTOR_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i = 3; i < n - 3; i++) {\n",
        "    if(Y[i] != (X[i - 3] + X[i - 2] + X[i - 1] + X[i] + X[i + 1] + X[i + 2] + X[i + 3]))\n",
        "      ++err_count;\n",
        "  }\n",
        "  printf(\"Error count (CUDA program): %d \\n\\n\", err_count);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(X);\n",
        "  cudaFree(Y);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc stencil_CUDA_2-30.cu -o stencil_CUDA_2-30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595c87bf-c8fb-4366-91d6-927fec794c70",
        "id": "sg2oWuPAq4o9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./stencil_CUDA_2-30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6311aecf-d3b3-4ad5-9335-02bd829ffece",
        "id": "KDuTymakq4o9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1664== NVPROF is profiling process 1664, command: ./stencil_CUDA_2-30\n",
            "\n",
            "=== 1-D Stencil ===\n",
            "Number of elements (n):  1073741824\n",
            "Byte size per vector:  8589934592\n",
            "Number of runs:  30\n",
            "\n",
            "Num. of Threads = 1024\n",
            "Num. of Blocks = 1048576\n",
            "Device # = 0\n"
          ]
        }
      ]
    }
  ]
}